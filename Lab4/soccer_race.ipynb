{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 - Applied ML\n",
    "\n",
    "There are four aspects:\n",
    "* First, we process the data and explore the dataset (0).\n",
    "* Then, we classify labels. (1).\n",
    "* We plot learning curves (Bonus)\n",
    "* Finally, we do clustering (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Pre-Processing and Visualization\n",
    "Understanding the dataset, cleaning the variables. This is important because later we will need clean data for supervised and unsupervised learning.\n",
    "\n",
    "Using http://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb, we will clean the dataset. Then, we will aggregate information. Finally, we will clean up the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Tasks and Outline\n",
    "\n",
    "1) Dataset cleaning\n",
    "- exclude interactions by  ref who feature in fewer than 22 diyads\n",
    "\n",
    "- drop NAs with no race values, averaging race values\n",
    "\n",
    "2) Aggregate to player data\n",
    "\n",
    "- combine games, referee and bias information using variable statistics\n",
    "\n",
    "3) Cleaning features\n",
    "\n",
    "- take out unnecessary features â€” player ID, photo ID\n",
    "- turning date into proper format\n",
    "\n",
    "- convert categorical variables into dummy variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dyads: 146028\n"
     ]
    }
   ],
   "source": [
    "orig_num_dyads = df.shape[0]\n",
    "print('number of dyads:', orig_num_dyads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This line defines a new dataframe based on our >21 games filter\n",
    "all_refs = df.refNum.value_counts()\n",
    "good_refs = all_refs[all_refs>21]\n",
    "\n",
    "df=df[df['refNum'].isin(good_refs.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of dyads left: 91.4215082039061\n"
     ]
    }
   ],
   "source": [
    "print('percentage of dyads left:', 100 * df.shape[0] / orig_num_dyads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Race Values\n",
    "\n",
    "Get the real \"race value\" by taking the average of the two. Then drop the ones that don't have rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['race_val'] = df['rater1'] + df['rater2']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['race_val'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of dyads left: 77.9727175610157\n"
     ]
    }
   ],
   "source": [
    "# Percentage of data left...\n",
    "print('percentage of dyads left:', 100 * df.shape[0] / orig_num_dyads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['rater1','rater2'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregating into Players\n",
    "\n",
    "We have three types of data, games, referee reference, and bias scores.\n",
    "\n",
    "We sum up the games. For referee, we need to be more careful.\n",
    "\n",
    "* refCountry cannot be averaged, but can take the mode.\n",
    "* Alpha_3 is just the ref country, so we take the mode as well\n",
    "* meanIAT and meanExp  are averaged\n",
    "* nIAT and nExp are summed\n",
    "* seIAT and seExp are done using functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>player</th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>john-utaka</td>\n",
       "      <td>John Utaka</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>France</td>\n",
       "      <td>08.01.1982</td>\n",
       "      <td>179.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Right Winger</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    playerShort      player             club leagueCountry    birthday  \\\n",
       "973  john-utaka  John Utaka  Montpellier HSC        France  08.01.1982   \n",
       "\n",
       "     height  weight      position  games  victories  ties  defeats  goals  \n",
       "973   179.0    82.0  Right Winger      1          0     0        1      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrating the columns of a single player\n",
    "df[df['player'] == 'John Utaka'].ix[:,0:13].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "      <th>photoID</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "      <th>race_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1663.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>LUX</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     yellowCards  yellowReds  redCards   photoID  refNum  refCountry Alpha_3  \\\n",
       "973            0           0         0  1663.jpg      66           4     LUX   \n",
       "\n",
       "      meanIAT   nIAT     seIAT   meanExp   nExp     seExp  race_val  \n",
       "973  0.325185  127.0  0.003297  0.538462  130.0  0.013752     1.125  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['player'] == 'John Utaka'].ix[:,13:28].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# each set of columns will be aggregated differently\n",
    "player_cols = ['playerShort'] # basis\n",
    "game_cols = ['games','victories','ties','defeats','goals','yellowCards','yellowReds','redCards'] #sum\n",
    "ref_cols = ['refCountry','Alpha_3'] #mode\n",
    "bias_mean_cols = ['meanIAT','meanExp'] #mean\n",
    "bias_n_cols = ['nIAT','nExp'] #sum\n",
    "bias_se_cols = ['seIAT', 'seExp'] #special function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated DataFrame\n",
    "\n",
    "* df_aggregated -- contains all the columns transformed by the groupby\n",
    "* df_player -- combines player columns with df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_aggregated = df.groupby(player_cols)[game_cols].sum().reset_index()\n",
    "df_aggregated = df_aggregated.merge(df.groupby(player_cols)[ref_cols].agg(lambda x: x.value_counts().index[0]).reset_index()) # refs\n",
    "df_aggregated = df_aggregated.merge(df.groupby(player_cols)[bias_mean_cols].mean().reset_index()) # bias mean\n",
    "df_aggregated = df_aggregated.merge(df.groupby(player_cols)[bias_n_cols].sum().reset_index()) #bias n\n",
    "df_aggregated = df_aggregated.merge(df.groupby(player_cols)[bias_se_cols].std().reset_index()) #bias std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>seExp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaron-hughes</td>\n",
       "      <td>641</td>\n",
       "      <td>243</td>\n",
       "      <td>176</td>\n",
       "      <td>222</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>0.344759</td>\n",
       "      <td>0.487879</td>\n",
       "      <td>3133820.0</td>\n",
       "      <td>3281187.0</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.003308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaron-hunt</td>\n",
       "      <td>329</td>\n",
       "      <td>140</td>\n",
       "      <td>70</td>\n",
       "      <td>119</td>\n",
       "      <td>59</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>DEU</td>\n",
       "      <td>0.349332</td>\n",
       "      <td>0.453989</td>\n",
       "      <td>2553329.0</td>\n",
       "      <td>2627685.0</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.002356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron-lennon</td>\n",
       "      <td>412</td>\n",
       "      <td>200</td>\n",
       "      <td>97</td>\n",
       "      <td>115</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>0.345893</td>\n",
       "      <td>0.491482</td>\n",
       "      <td>2144721.0</td>\n",
       "      <td>2246113.0</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.008723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron-ramsey</td>\n",
       "      <td>254</td>\n",
       "      <td>145</td>\n",
       "      <td>42</td>\n",
       "      <td>67</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>0.346790</td>\n",
       "      <td>0.511650</td>\n",
       "      <td>3975720.0</td>\n",
       "      <td>4124639.0</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdelhamid-el-kaoutari</td>\n",
       "      <td>124</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>FRA</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.335587</td>\n",
       "      <td>104797.0</td>\n",
       "      <td>109292.0</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.023134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              playerShort  games  victories  ties  defeats  goals  \\\n",
       "0            aaron-hughes    641        243   176      222      9   \n",
       "1              aaron-hunt    329        140    70      119     59   \n",
       "2            aaron-lennon    412        200    97      115     31   \n",
       "3            aaron-ramsey    254        145    42       67     39   \n",
       "4  abdelhamid-el-kaoutari    124         41    40       43      1   \n",
       "\n",
       "   yellowCards  yellowReds  redCards  refCountry Alpha_3   meanIAT   meanExp  \\\n",
       "0           19           0         0          44    ENGL  0.344759  0.487879   \n",
       "1           39           0         1           8     DEU  0.349332  0.453989   \n",
       "2           11           0         0          44    ENGL  0.345893  0.491482   \n",
       "3           31           0         1          44    ENGL  0.346790  0.511650   \n",
       "4            8           4         2           7     FRA  0.331600  0.335587   \n",
       "\n",
       "        nIAT       nExp     seIAT     seExp  \n",
       "0  3133820.0  3281187.0  0.000707  0.003308  \n",
       "1  2553329.0  2627685.0  0.000508  0.002356  \n",
       "2  2144721.0  2246113.0  0.001220  0.008723  \n",
       "3  3975720.0  4124639.0  0.001406  0.009682  \n",
       "4   104797.0   109292.0  0.006216  0.023134  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_cols = ['playerShort','player','club','leagueCountry','birthday','height','weight','position'] # basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_player = df[player_cols].drop_duplicates().merge(df_aggregated,how='inner',on='playerShort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Features\n",
    "Remove:\n",
    "- playerID and photoID - already removed in the aggregation process\n",
    "- refCountry - it is bijective with Alpha_3.\n",
    "- playerShort, player - because they are just names\n",
    "\n",
    "Process:\n",
    "- birthday - convert to date\n",
    "\n",
    "Dummy Variables:\n",
    "- club\n",
    "- leagueCountry\n",
    "- position\n",
    "- refCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a new dataframe for machine learning later\n",
    "df_ml = df_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ml.drop(['playerShort','player','refCountry'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert into datetime format\n",
    "df_ml['birthay'] = pd.to_datetime(df_ml['birthday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn categorical variables into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "club = pd.get_dummies(df_ml['club'])\n",
    "leagueCountry = pd.get_dummies(df_ml['leagueCountry'])\n",
    "position = pd.get_dummies(df_ml['position'])\n",
    "refCountry = pd.get_dummies(df_ml['Alpha_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_variables = [df_ml, club, leagueCountry, position, refCountry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ml = pd.concat(dummy_variables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>...</th>\n",
       "      <th>FIN</th>\n",
       "      <th>FRA</th>\n",
       "      <th>GRC</th>\n",
       "      <th>HUN</th>\n",
       "      <th>ISL</th>\n",
       "      <th>ITA</th>\n",
       "      <th>KOR</th>\n",
       "      <th>NLD</th>\n",
       "      <th>PRT</th>\n",
       "      <th>SCOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>England</td>\n",
       "      <td>08.11.1979</td>\n",
       "      <td>182.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>641</td>\n",
       "      <td>243</td>\n",
       "      <td>176</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manchester City</td>\n",
       "      <td>England</td>\n",
       "      <td>10.11.1985</td>\n",
       "      <td>187.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Left Fullback</td>\n",
       "      <td>275</td>\n",
       "      <td>134</td>\n",
       "      <td>55</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norwich City</td>\n",
       "      <td>England</td>\n",
       "      <td>04.04.1986</td>\n",
       "      <td>180.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Defensive Midfielder</td>\n",
       "      <td>198</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>England</td>\n",
       "      <td>13.04.1984</td>\n",
       "      <td>193.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Goalkeeper</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1899 Hoffenheim</td>\n",
       "      <td>Germany</td>\n",
       "      <td>13.03.1987</td>\n",
       "      <td>180.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Right Fullback</td>\n",
       "      <td>294</td>\n",
       "      <td>124</td>\n",
       "      <td>71</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                club leagueCountry    birthday  height  weight  \\\n",
       "0          Fulham FC       England  08.11.1979   182.0    71.0   \n",
       "1    Manchester City       England  10.11.1985   187.0    80.0   \n",
       "2       Norwich City       England  04.04.1986   180.0    68.0   \n",
       "3  Manchester United       England  13.04.1984   193.0    80.0   \n",
       "4    1899 Hoffenheim       Germany  13.03.1987   180.0    70.0   \n",
       "\n",
       "               position  games  victories  ties  defeats  ...   FIN  FRA  GRC  \\\n",
       "0           Center Back    641        243   176      222  ...   0.0  0.0  0.0   \n",
       "1         Left Fullback    275        134    55       86  ...   0.0  0.0  0.0   \n",
       "2  Defensive Midfielder    198         80    50       68  ...   0.0  1.0  0.0   \n",
       "3            Goalkeeper     78         40    15       23  ...   0.0  0.0  0.0   \n",
       "4        Right Fullback    294        124    71       99  ...   0.0  0.0  0.0   \n",
       "\n",
       "   HUN  ISL  ITA  KOR  NLD  PRT  SCOT  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0   0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification\n",
    "### Training Random Forest\n",
    "### Parameter Fitting\n",
    "### Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus \n",
    "Learning Curves: Cross Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering\n",
    "### Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff People have done/Discussions on Slack:\n",
    "\n",
    "## First Discussion -- Input features\n",
    "Ismail Bensouda Koraichi\t[7:48 PM]  \n",
    "Hello, I would like to clarify something. In the first question of the homework : \" [...] given a soccer player description outputs his skin color\", what does \"soccer player description\" mean ? I mean what should be the input ? A dyad ? An aggregation of multiple dyads ?\n",
    "\n",
    "Gael Lederrey\t[9:24 PM]  \n",
    "@ismail64 I think that we'll have to aggregate the data by players.. But then, we loose some information (the IAT and Exp for examples).. Therefore, it can be interesting to create a new feature taking into account the removed feature..\n",
    "\n",
    "But maybe there's another way to deal with the data without aggregating them.. =)\n",
    "\n",
    "Dunai Fuentes Hitos\t[11:31 PM]  \n",
    "I went with the aggregation by player.\n",
    "The \"smart\" way to deal with those features (IAT, Exp, etc.) would be to make a correction upon the number of yellow and red cards received by the player, as this is the only link players have to the referee...\n",
    "But it all looks a bit far-fetched, so I particularly decided to remove all this data under a presumption of honesty (the referee's honesty) (edited)\n",
    "\n",
    "Gael Lederrey\t[11:57 PM]  \n",
    "@dunai That's what I did too.. ^^ \n",
    "But I'm pretty sure racism exists everywhere. So I just created a weighted sum for the cards, the referees' \"racism\" values, and the number of times they encountered a player.. This gives you sort of a score linking the _IAT_ and the _Exp_ to all the referees who encounter a player..\n",
    "\n",
    "At the end, I'm pretty sure that it's important to keep these values.. Because the other values (goals, height, weight, games, etc.) can't be linked to the color of a player.. So, there's only these two \"racism\" values linked to the number of cards that can maybe give some information..\n",
    "\n",
    "If someone has another idea, I'd be glad to read about it.. =) (edited)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Discussion - Aggregating Features\n",
    "\n",
    "Jonas Racine\t[3:39 PM]  \n",
    "hey guys, is anyone able to get much more than ~70% accuracy on the homework? (exercise 1)\n",
    "\n",
    "bojan.petrovski\t[3:42 PM]  \n",
    "I got something like 78-80\n",
    "\n",
    "[3:43]  \n",
    "But I'm aggregating the results by player\n",
    "\n",
    "Gael Lederrey\t[3:53 PM]  \n",
    "@bojan.petrovski Did you create new features using the ones we loose (Like the IAT and Exp)?\n",
    "\n",
    "bojan.petrovski\t[4:14 PM]  \n",
    "Yeah for the IATmean and EXPmean I averaged them and for IATstd and EXPstd I calculated the Stadndard deviation on the samples that I used for the new means, because you can't just average standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Third Discussion - Dealing with Categorical Features\n",
    "\n",
    "Paul Nicolet\t[10:01 AM]  \n",
    "Hey guys Iâ€™m curious to know if you have a good way to deal with the categorical features in the homework, as `scikit-learn` doesnâ€™t accept them as strings. I figured out a way to encode them using the `OneHotEncoder()` class, in order to get a vector representation of each category, but I have some issues to deal with these vectors now, given a DataFrame doesnâ€™t accept vectors as valuesâ€¦ The easy way would be to encode them as integers but itâ€™s risky because it could be interpreted as continuous and ordered data right ?\n",
    "\n",
    "arnaudmiribel\t[10:05 AM]  \n",
    "Weâ€™ve used `LabelEncoder()` which naÃ¯vely binds labels to integers values. There are some issues doing this as two successive cells will be numerically _closer_ than two far apart cells (whereas there is no reason for this), so Iâ€™d also welcome any hint on this\n",
    "\n",
    "Baptiste Billardon\t[10:08 AM]  \n",
    "From what I read, there are no implementation of random forest in sklearn that handles categorical features. I also labelEncoded the categorical features then oneHotEncoded them\n",
    "\n",
    "Ondine Chanon\t[11:20 AM]  \n",
    "And what about dummy variables? It increases the number of attributes, but at least each cell has equal importance and there is no ordering issue.\n",
    "\n",
    "Ciprian Tomoiaga\t[3:53 PM]  \n",
    "@bojan.petrovski what would be the reason for averaging IATmean (or EXPmean) ?\n",
    "\n",
    "[3:55]  \n",
    "I mean, it's great that you get a good score, but it doesn't make much sense to me to average independent values. I mean, they are not related to the player, but to the referee\n",
    "\n",
    "Alexis Semple\t[4:25 PM]  \n",
    "Hey guys, I wonder how you understood the first sentence of the description for exercise 2 in this homework:\n",
    "> Aggregate the _referee information_ grouping by soccer player\n",
    "Maybe I'm missing something, but it seems to me that this indicates that we should not use features relevant only to the player himself (e.g. height, weight, position...) (edited)\n",
    "\n",
    "Gianrocco Lazzari\t[4:49 PM]  \n",
    "well, in principle I donâ€™t see what you should exclude themâ€¦itâ€™s about reducing the variability across referees (the way I understand it) - it might  be that  player-dependent-features are still relevant (edited)\n",
    "\n",
    "bojan.petrovski\t[5:19 PM]  \n",
    "@cipri_tom well in an ideal world the distribution of red and yellow cards should only depend on the position of the player, i.e. defenders are more likely to make a serious offence. So the cards alone should not help in any way to distinguish between black and white players. My idea is that some referees have a bias so the distribution is not the same for black and white players. And the average of the IAT just gives you a very crude idea of how much the player was discriminated against. For example if the average IAT is high and the player is black I would expect the distribution of cards for that player to be very different and if the IAT is low than you would expect the difference to be small in relation to the distribution for white players. I saw some people mention doing a weighted average based on the number of cards, but I think that in that way you are skewing the average because the lack of a card is also valuable information. (edited)\n",
    "\n",
    "[5:20]  \n",
    "But again it's hard to tell if the model is actually doing this kind of prediction or is picking up on some other factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
